{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjeff\\AppData\\Local\\Temp\\ipykernel_162828\\1161532954.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "second must be in 0..59: 0:10:95, at position 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 649\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_naive(res, default)\n\u001b[0;32m    650\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1235\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1233\u001b[0m         repl[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m monthrange(cyear, cmonth)[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1235\u001b[0m naive \u001b[39m=\u001b[39m default\u001b[39m.\u001b[39mreplace(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrepl)\n\u001b[0;32m   1237\u001b[0m \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39mweekday \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m res\u001b[39m.\u001b[39mday:\n",
      "\u001b[1;31mValueError\u001b[0m: second must be in 0..59",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tjeff\\Documents\\Untitled-1.ipynb Cellule 1\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tjeff/Documents/Untitled-1.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mpp.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tjeff/Documents/Untitled-1.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Convertir la colonne timestamp en type datetime\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tjeff/Documents/Untitled-1.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(data[\u001b[39m\"\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tjeff/Documents/Untitled-1.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Encoder les variables catégorielles\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tjeff/Documents/Untitled-1.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1050\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1049\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1050\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   1051\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   1052\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:455\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 455\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m    458\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m    459\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m    460\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray(result, dtype\u001b[39m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[0;32m   2174\u001b[0m \u001b[39m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mobject_)\n\u001b[1;32m-> 2177\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39;49marray_to_datetime(\n\u001b[0;32m   2178\u001b[0m     data,\n\u001b[0;32m   2179\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   2180\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[0;32m   2181\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m   2182\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m   2183\u001b[0m )\n\u001b[0;32m   2185\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2186\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m     \u001b[39m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2188\u001b[0m     \u001b[39m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m), tz_parsed\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:402\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:516\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:557\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tjeff\\miniconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:311\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[39mreturn\u001b[39;00m parser(parserinfo)\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[39mreturn\u001b[39;00m DEFAULTPARSER\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:651\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_naive(res, default)\n\u001b[0;32m    650\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 651\u001b[0m     six\u001b[39m.\u001b[39;49mraise_from(ParserError(\u001b[39mstr\u001b[39;49m(e) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m: \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, timestr), e)\n\u001b[0;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignoretz:\n\u001b[0;32m    654\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tzaware(ret, res, tzinfos)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: second must be in 0..59: 0:10:95, at position 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%H:%M:%S:%f\")\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Enregistrer les données au format CSV\n",
    "data.to_csv(\"pp_updated.csv\", index=False)\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.hour * 3600 + data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"pp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Id_Website  100 non-null    int64 \n",
      " 1   Id_proxy    100 non-null    int64 \n",
      " 2   Success     100 non-null    bool  \n",
      " 3   timestamp   100 non-null    object\n",
      "dtypes: bool(1), int64(2), object(1)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.8\n",
      "Matrice de confusion :\n",
      " [[15  0]\n",
      " [ 4  1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.hour * 3600 + data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.75\n",
      "Matrice de confusion :\n",
      " [[15  0]\n",
      " [ 5  0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"new_data.csv\")\n",
    "\n",
    "# Prétraiter les nouvelles données\n",
    "# Assurez-vous d'appliquer les mêmes transformations que pour les données d'entraînement\n",
    "new_data[\"timestamp\"] = pd.to_datetime(new_data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "new_data[\"tierces\"] = new_data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "new_data[\"time_elapsed\"] = new_data[\"timestamp\"].dt.minute * 60 + new_data[\"timestamp\"].dt.second\n",
    "# Sélectionner les mêmes variables prédictives que pour l'entraînement\n",
    "X_new = new_data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "\n",
    "# Faire les prédictions sur les nouvelles données\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les valeurs minimales et maximales des variables d'entraînement\n",
    "min_id_website = X_train[\"Id_Website\"].min()\n",
    "max_id_website = X_train[\"Id_Website\"].max()\n",
    "\n",
    "min_id_proxy = X_train[\"Id_proxy\"].min()\n",
    "max_id_proxy = X_train[\"Id_proxy\"].max()\n",
    "\n",
    "min_time_elapsed = X_train[\"time_elapsed\"].min()\n",
    "max_time_elapsed = X_train[\"time_elapsed\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les nouvelles données depuis le fichier CSV\n",
    "new_data = pd.read_csv(\"new_data.csv\")\n",
    "\n",
    "# Prétraiter les nouvelles données\n",
    "# Assurez-vous d'appliquer les mêmes transformations que pour les données d'entraînement\n",
    "new_data[\"timestamp\"] = pd.to_datetime(new_data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "new_data[\"tierces\"] = new_data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "new_data[\"time_elapsed\"] = new_data[\"timestamp\"].dt.minute * 60 + new_data[\"timestamp\"].dt.second\n",
    "\n",
    "# Normaliser les nouvelles données\n",
    "new_data[\"Id_Website\"] = (new_data[\"Id_Website\"] - min_id_website) / (max_id_website - min_id_website)\n",
    "new_data[\"Id_proxy\"] = (new_data[\"Id_proxy\"] - min_id_proxy) / (max_id_proxy - min_id_proxy)\n",
    "new_data[\"time_elapsed\"] = (new_data[\"time_elapsed\"] - min_time_elapsed) / (max_time_elapsed - min_time_elapsed)\n",
    "\n",
    "# Sélectionner les mêmes variables prédictives que pour l'entraînement\n",
    "X_new = new_data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "\n",
    "# Faire les prédictions sur les nouvelles données\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"new_data.csv\")\n",
    "\n",
    "# Prétraiter les nouvelles données\n",
    "# Assurez-vous d'appliquer les mêmes transformations que pour les données d'entraînement\n",
    "new_data[\"timestamp\"] = pd.to_datetime(new_data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "new_data[\"time_elapsed\"] = new_data[\"timestamp\"].dt.minute * 60 + new_data[\"timestamp\"].dt.second\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "new_data[\"Success\"] = label_encoder.transform(new_data[\"Success\"])\n",
    "\n",
    "# Sélectionner les mêmes variables prédictives que pour l'entraînement\n",
    "X_new = new_data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "\n",
    "# Faire les prédictions sur les nouvelles données\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
