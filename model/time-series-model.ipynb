{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mpp.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Convertir la colonne timestamp en type datetime\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data[\u001b[39m\"\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS:\u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtierces\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mmicrosecond \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Encoder les variables catégorielles\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%H:%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Enregistrer les données au format CSV\n",
    "data.to_csv(\"pp_updated.csv\", index=False)\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict_proba(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mpp.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Convert the timestamp column to datetime type\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data[\u001b[39m\"\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Create a new column \"time_elapsed\" in seconds\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kzd/Smart-Proxy-Provider-SQL/model/time-series-model.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtime_elapsed\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mhour \u001b[39m*\u001b[39m \u001b[39m3600\u001b[39m \u001b[39m+\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mminute \u001b[39m*\u001b[39m \u001b[39m60\u001b[39m \u001b[39m+\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39msecond\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"pp.csv\")\n",
    "\n",
    "# Convert the timestamp column to datetime type\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "\n",
    "# Create a new column \"time_elapsed\" in seconds\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.hour * 3600 + data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second\n",
    "\n",
    "# Label encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Separate the predictor variables from the target variable\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Model accuracy:\", accuracy)\n",
    "print(\"Confusion matrix:\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 799 entries, 0 to 798\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Id_Website  799 non-null    int64 \n",
      " 1   Id_proxy    799 non-null    int64 \n",
      " 2   Success     799 non-null    bool  \n",
      " 3   timestamp   799 non-null    object\n",
      "dtypes: bool(1), int64(2), object(1)\n",
      "memory usage: 19.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.7625\n",
      "Matrice de confusion :\n",
      " [[108   8]\n",
      " [ 30  14]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.hour * 3600 + data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.7625\n",
      "Matrice de confusion :\n",
      " [[106  10]\n",
      " [ 28  16]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       57\n",
       "1       26\n",
       "2      105\n",
       "3       76\n",
       "4       50\n",
       "      ... \n",
       "794     17\n",
       "795    254\n",
       "796     24\n",
       "797    194\n",
       "798    131\n",
       "Name: time_elapsed, Length: 799, dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"time_elapsed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_Website</th>\n",
       "      <th>Id_proxy</th>\n",
       "      <th>Success</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>0:32:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0:01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>0:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>0:38:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>395</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>0:04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>724</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>0:02:93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>452</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0:22:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0:50:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>160</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>3:10:75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>448</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3:08:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id_Website  Id_proxy  Success timestamp\n",
       "0           388        24    False   0:32:13\n",
       "1            72        11    False   0:01:40\n",
       "2           424        31     True   0:21:18\n",
       "3           714        35    False   0:38:13\n",
       "4           395        35    False   0:04:37\n",
       "..          ...       ...      ...       ...\n",
       "196         724        58    False   0:02:93\n",
       "197         452         2    False   0:22:18\n",
       "198           5         5    False   0:50:08\n",
       "199         160        23    False   3:10:75\n",
       "200         448         5    False   3:08:51\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(\"new_data.csv\", delimiter=\"\\t\")\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201 entries, 0 to 200\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Id_Website  201 non-null    int64 \n",
      " 1   Id_proxy    201 non-null    int64 \n",
      " 2   Success     201 non-null    bool  \n",
      " 3   timestamp   201 non-null    object\n",
      "dtypes: bool(1), int64(2), object(1)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#new_data = pd.read_csv(\"new_data.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Prétraiter les nouvelles données\n",
    "# Assurez-vous d'appliquer les mêmes transformations que pour les données d'entraînement\n",
    "new_data[\"timestamp\"] = pd.to_datetime(new_data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "new_data[\"tierces\"] = new_data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "new_data[\"time_elapsed\"] = new_data[\"timestamp\"].dt.minute * 60 + new_data[\"timestamp\"].dt.second\n",
    "# Sélectionner les mêmes variables prédictives que pour l'entraînement\n",
    "X_new = new_data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "\n",
    "# Faire les prédictions sur les nouvelles données\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Afficher les prédictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[\"Success\"] = label_encoder.fit_transform(new_data[\"Success\"])\n",
    "\n",
    "target = new_data[\"Success\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0, -1,  1,  1,  0,  0,  0,\n",
       "        0,  0, -1, -1,  0,  1, -1,  0,  1,  0,  0,  0, -1,  0, -1, -1,  0,\n",
       "       -1,  0,  0,  0, -1,  0,  1,  0,  0, -1,  0,  0,  0,  1,  0,  0,  0,\n",
       "       -1,  0,  0, -1,  0, -1,  1,  0,  1,  1, -1,  0,  0,  0, -1,  0,  0,\n",
       "        1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0, -1,  0,\n",
       "        0,  0, -1,  0, -1,  0,  1,  1,  0,  0, -1,  0,  0,  0,  1, -1,  0,\n",
       "       -1, -1,  0,  0,  0,  0,  0, -1,  0, -1,  0,  0,  0,  0,  0,  1,  0,\n",
       "        1,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0, -1,  1,\n",
       "        0,  0,  0,  0, -1,  1,  1, -1,  1, -1,  0, -1, -1,  0,  0,  0,  0,\n",
       "        0,  0, -1,  1,  1, -1,  0,  0,  0, -1,  0, -1,  0,  0,  0,  0,  0,\n",
       "        0, -1,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions - target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.6766169154228856\n",
      "Matrice de confusion :\n",
      " [[134  21]\n",
      " [ 44   2]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(target, predictions)\n",
    "confusion_mat = confusion_matrix(target, predictions)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.74375\n",
      "Matrice de confusion :\n",
      " [[110   6]\n",
      " [ 35   9]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = GradientBoostingClassifier()\n",
    "pipeline_model6 = make_pmml_pipeline(model)\n",
    "pipeline_model6.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline_model6.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model6, \"trained_model6.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.725\n",
      "Matrice de confusion :\n",
      " [[116   0]\n",
      " [ 44   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle SVM\n",
    "model = SVC()\n",
    "pipeline_model5 = make_pmml_pipeline(model)\n",
    "pipeline_model5.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline_model5.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model5, \"trained_model5.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.7125\n",
      "Matrice de confusion :\n",
      " [[94 22]\n",
      " [24 20]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline_model4 = make_pmml_pipeline(model)\n",
    "pipeline_model4.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline_model4.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model4, \"trained_model4.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.725\n",
      "Matrice de confusion :\n",
      " [[104  12]\n",
      " [ 32  12]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_model3 = make_pmml_pipeline(model)\n",
    "pipeline_model3.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline_model3.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model3, \"trained_model3.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.74375\n",
      "Matrice de confusion :\n",
      " [[115   1]\n",
      " [ 40   4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "model = MLPClassifier()\n",
    "pipeline_model2 = make_pmml_pipeline(model)\n",
    "pipeline_model2.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline_model2.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model2, \"trained_model2.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.725\n",
      "Matrice de confusion :\n",
      " [[116   0]\n",
      " [ 44   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle SVM\n",
    "model = SGDClassifier()\n",
    "pipeline_model7 = make_pmml_pipeline(model)\n",
    "pipeline_model7.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline_model7.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model7, \"trained_model7.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 0.725\n",
      "Matrice de confusion :\n",
      " [[116   0]\n",
      " [ 44   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "\n",
    "# Charger le fichier CSV\n",
    "data = pd.read_csv(\"pp.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Convertir la colonne timestamp en type datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], format=\"%M:%S:%f\")\n",
    "data[\"tierces\"] = data[\"timestamp\"].dt.microsecond // 10000\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Success\"] = label_encoder.fit_transform(data[\"Success\"])\n",
    "\n",
    "# Créer une nouvelle colonne \"time_elapsed\" en secondes\n",
    "data[\"time_elapsed\"] = data[\"timestamp\"].dt.minute * 60 + data[\"timestamp\"].dt.second + data[\"tierces\"]\n",
    "\n",
    "# Séparer les variables prédictives de la variable cible\n",
    "X = data[[\"Id_Website\", \"Id_proxy\", \"time_elapsed\"]]\n",
    "y = data[\"Success\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser et entraîner le modèle SVM\n",
    "model = LogisticRegression()\n",
    "pipeline_model8 = make_pmml_pipeline(model)\n",
    "pipeline_model8.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred_proba = pipeline_model8.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "# print(y_pred_proba)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(\"Matrice de confusion :\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "sklearn2pmml(pipeline_model8, \"trained_model8.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id_Website  Id_proxy  time_elapsed    Prob_0    Prob_1\n",
      "0             7        21            81  0.745024  0.254976\n",
      "1            38        38           206  0.716569  0.283431\n",
      "2           684        42            47  0.772487  0.227513\n",
      "3           231        12           124  0.723996  0.276004\n",
      "4           190        50            79  0.767657  0.232343\n",
      "..          ...       ...           ...       ...       ...\n",
      "155         351        39            93  0.755498  0.244502\n",
      "156         261        46           194  0.727650  0.272350\n",
      "157         578        44           124  0.749816  0.250184\n",
      "158         267        13            78  0.740302  0.259698\n",
      "159          66        10            80  0.736903  0.263097\n",
      "\n",
      "[160 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert y_pred_proba to DataFrame\n",
    "y_pred_proba_df = pd.DataFrame(y_pred_proba, columns=['Prob_0', 'Prob_1'])\n",
    "\n",
    "# Reset index of X_test for proper concatenation\n",
    "X_test_reset = X_test.reset_index(drop=True)\n",
    "\n",
    "# Concatenate along the column axis\n",
    "result = pd.concat([X_test_reset, y_pred_proba_df], axis=1)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab1b7e499733aeb9486d48c7e317ac98843d6bed1d3ecc58008cfbd0cfa40867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
